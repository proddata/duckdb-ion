# Performance Baseline (read_ion vs read_json)

## Goal
Establish a repeatable baseline comparing `read_ion` to `read_json` on equivalent data and queries, without changing implementation yet.

## Step 1: Prepare comparable datasets
- Use the same schema and record count for Ion (newline‑delimited structs) and JSONL.
- If needed, export from DuckDB once and convert:
  - `COPY (SELECT * FROM my_table) TO 'data.ion' (FORMAT ION);`
  - `COPY (SELECT * FROM my_table) TO 'data.jsonl' (FORMAT JSON);`
- Or use the helper script to generate both:
  - `ROWS=100000 OUT_DIR=perf/data ./scripts/perf_generate.sh`
  - Re-run this script whenever serialization rules change.
  - Wide schema fixtures are also emitted as `data_wide.ion` and `data_wide.jsonl`.
  - When ion-c is available via vcpkg, the script also emits `data_binary.ion` and `data_wide_binary.ion`.

## Step 2: Run standardized queries
Pick at least three queries and run each on both formats:
1. Full scan count
   - `SELECT COUNT(*) FROM read_ion('data.ion');`
   - `SELECT COUNT(*) FROM read_json('data.jsonl');`
2. Projection
   - `SELECT col1, col2 FROM read_ion('data.ion');`
   - `SELECT col1, col2 FROM read_json('data.jsonl');`
3. Filter + aggregate
   - `SELECT col1, COUNT(*) FROM read_ion('data.ion') WHERE col2 > 10 GROUP BY col1;`
   - `SELECT col1, COUNT(*) FROM read_json('data.jsonl') WHERE col2 > 10 GROUP BY col1;`

## Step 3: Capture profiling output
Use DuckDB’s built‑in profiling:
```sql
PRAGMA enable_profiling='json';
PRAGMA profiling_output='ion_profile.json';
SELECT COUNT(*) FROM read_ion('data.ion');

PRAGMA profiling_output='json_profile.json';
SELECT COUNT(*) FROM read_json('data.jsonl');
```
Repeat for the other queries (use distinct profiling_output files).

## Step 4: Record baseline numbers
For each query, capture:
- wall time (from client or shell timing)
- rows/sec (if your client reports it)
- top operators from profiling output

## Step 5: Identify hotspots
Common hotspots to look for:
- per‑value conversions and casts
- recursive list/struct parsing
- string conversion for timestamps/decimals/blobs

## Step 6: Keep a log
Keep a simple table (spreadsheet or markdown) with:
- dataset size + row count
- query name
- read_ion time / read_json time
- notes on hotspots from profiling
You can run the standard set with:
- `DATA_DIR=perf/data OUT_DIR=perf/results ./scripts/perf_run.sh`
- Set `ION_PROFILE=1` to emit a `read_ion` internal timing breakdown to stdout.

## Current Baseline (2M Rows)
The latest apples-to-apples comparison (same dataset, same query shape) from `perf/results/` shows Ion is still
slower than JSON. These were run against the newline-delimited datasets generated by `scripts/perf_generate.sh`.

Ion vs JSON ratios are computed as `Ion / JSON` using the profile JSON fields (`cpu_time`, `latency`).

| Query | Ion CPU | JSON CPU | CPU Ratio | Ion Latency | JSON Latency | Latency Ratio |
| --- | --- | --- | --- | --- | --- | --- |
| COUNT(*) | 2.144s | 0.433s | 4.96x | 2.147s | 0.075s | 28.69x |
| Project 3 cols | 2.104s | 0.434s | 4.85x | 2.116s | 0.072s | 29.42x |
| Filter + group | 2.086s | 0.342s | 6.10x | 2.092s | 0.059s | 35.17x |
| Wide schema (4 cols) | 8.765s | 2.838s | 3.09x | 8.782s | 0.375s | 23.42x |

Sources:
- `perf/results/ion_count.json`, `perf/results/json_count.json`
- `perf/results/ion_project.json`, `perf/results/json_project.json`
- `perf/results/ion_filter_agg.json`, `perf/results/json_filter_agg.json`
- `perf/results/ion_project_wide.json`, `perf/results/json_project_wide.json`

Notes:
- Total bytes read are similar between Ion and JSON; the gap is dominated by parsing and value materialization cost.
- Parallel newline-delimited runs are tracked separately (`*_nd_parallel.json`) and are not included above.

## Profiling Insights (2M Rows)
Internal `read_ion` profiling (`profile := true`) shows the hottest areas are reader traversal and struct iteration,
not value conversion. Example on `perf/data/data.ion`:

- `SELECT COUNT(*) FROM read_ion(..., profile := true)` (projected `id` only):
  - `next_ms ~1076`, `struct_ms ~945`, `value_ms ~37`
  - 2M rows, 2M fields visited (early exit after `id`)
- `SELECT id, category, amount::DOUBLE FROM read_ion(..., profile := true)`:
  - `next_ms ~727`, `struct_ms ~1434`, `value_ms ~233`
  - 2M rows, 6M fields visited

Takeaways:
- Field traversal + name/SID resolution dominate (`next_ms` + `struct_ms`).
- Value conversion is comparatively small when vector paths succeed.
- Narrow projections still pay per-field traversal until all projected fields are seen.
## Key Takeaways
- Text Ion remains ~3–4x slower than JSON on CPU and much slower on latency, pointing to per-row materialization overhead.
- Binary Ion is competitive (or faster) on CPU versus JSON text for comparable queries, but latency still lags.
- The largest absolute wins are from binary Ion on wide schemas, where text parsing overhead dominates.
- Parallelism helps throughput but does not close the per-row overhead gap for text Ion.

## Binary Ion Baseline (2M Rows)
Binary Ion files are generated from the text files using `scripts/ion_text_to_binary.cpp` (built in
`scripts/perf_generate.sh`). These runs compare `read_ion` on text vs binary Ion only.

| Query | Text CPU | Binary CPU | Speedup | Text Latency | Binary Latency | Speedup |
| --- | --- | --- | --- | --- | --- | --- |
| COUNT(*) | 2.144s | 0.790s | 2.72x | 2.147s | 0.791s | 2.71x |
| Project 3 cols | 2.104s | 1.139s | 1.85x | 2.116s | 1.146s | 1.85x |
| Wide COUNT(*) | 7.288s | 0.870s | 8.38x | 7.296s | 0.874s | 8.35x |
| Wide project (4 cols) | 8.765s | 2.305s | 3.80x | 8.782s | 2.316s | 3.79x |

Sources:
- `perf/results/ion_count.json`, `perf/results/ion_count_binary.json`
- `perf/results/ion_project.json`, `perf/results/ion_project_binary.json`
- `perf/results/ion_count_wide.json`, `perf/results/ion_count_wide_binary.json`
- `perf/results/ion_project_wide.json`, `perf/results/ion_project_wide_binary.json`

## Potential Improvements
- Enable projection pushdown to skip parsing unselected columns (mirrors `read_json` behavior).
- Batch-transform Ion values into vectors to reduce per-row `Value` allocations and casts.
- Cache field-to-column mappings beyond per-field SID lookup (e.g., stable field order heuristics).
- Consider `ION_READER_OPTIONS.skip_character_validation` for trusted data.
- Avoid string round-trips for decimals/timestamps by decoding Ion primitives directly.
- Parallelize newline-delimited scans to better utilize threads.

## Parallel Scan Notes
- Parallel scans currently only apply when `format='newline_delimited'` and the file is seekable.
- The perf suite now captures parallel JSON runs alongside Ion for apples-to-apples comparisons.
- Use `PRAGMA threads=<n>;` to force multiple threads during benchmarks.
